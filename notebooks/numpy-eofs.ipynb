{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ad7940-9c23-4fcf-95fe-e903ee56ecae",
   "metadata": {},
   "source": [
    "# EOFs with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3357b03-0648-4614-bd5d-40f35856904d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3794539-0066-4853-9ade-df6d75c52103",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In order to gain some familiarity with the method, this notebook will work through the EOF method step by step on some synthetic data. We will also see clearly some of the limitations of the method, including mode mixing {cite:p}`chen_pairwise-rotated_2017` and the generation of unphysical modes {cite:p}`dommenget_cautionary_2002`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75482cb4-279c-4394-b2f5-d57bdc1e0687",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Foundations NumPy section](https://foundations.projectpythia.org/core/numpy/) | Necessary | |\n",
    "| [Intro to EOFs](eof-intro) | Helpful | |\n",
    "\n",
    "- **Time to learn**: 20 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803f425-6e70-4623-ae3d-8cf597ced1f4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65985050-dbfe-4db5-b655-14334d77f3a6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3e9c3-afdb-4124-a7ff-ba8cab4f0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import CenteredNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70cfd1d-750a-4764-a664-099394ab3590",
   "metadata": {},
   "source": [
    "## Set the domain\n",
    "\n",
    "Assume a domain with two spatial dimensions, $x$ and $y$, and time $t$. For simplicity, we will start all dimensions at zero and increment by one up to some arbitrary maximum, here $x=9$, $y=19$, and $t=49$. Different dimension lengths will help highlight the shape of the data as we work through the EOF analysis. We are using `numpy.mgrid` to create our 3-dimensional domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435eedb7-e613-438b-94ad-e6c3c3940ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, t = np.mgrid[0:10, 0:20, 0:50]\n",
    "nx, ny, nt = x.shape[0], x.shape[1], x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0427b9-25e7-409e-a3e3-7fba52e0a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db1b25-df9e-459b-83d5-2f544c8c3813",
   "metadata": {},
   "source": [
    "## Generate some data\n",
    "\n",
    "Let's generate some \"modes of variability\" in the domain. We will combine them and then use an EOF analysis to pull them back apart. First, here is a 2-dimensional Gaussian that oscillates between positive and negative with a period of 25 time steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a93bf-dd91-460e-8ce9-a6f5553812b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_1 = 4*np.exp(-((x - np.mean(x))**2)/3 - ((y - np.mean(y))**2)/5) * np.cos(2*np.pi*t/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16abd9-d4cc-4820-b45f-959ce1003bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(x[:, :, 0], y[:, :, 0], mode_1[:, :, 0], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar()\n",
    "plt.ylabel('$y$')\n",
    "plt.xlabel('$x$')\n",
    "plt.title('Mode 1 at $t=0$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e8b0ae-caf6-4591-8776-657fc79f3076",
   "metadata": {},
   "source": [
    "To see how this mode changes over time, we can take the mean over the x-axis (a \"zonal\" mean), and plot it as a function of $y$ and $t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838dd0c-a42a-4425-b4e5-9c608b3fba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(t[0, :, :], y[0, :, :], mode_1.mean(axis=0), cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar()\n",
    "plt.ylabel('$y$')\n",
    "plt.xlabel('$t$')\n",
    "plt.title('Mode 1 zonal mean over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d82e33-fbf1-4068-8368-45420570ba73",
   "metadata": {},
   "source": [
    "Here is a second mode, which is the sum of cosines in $x$ and $y$ and oscillates between positive and negative with a period of 15 time steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437894b-b486-462b-afb3-c177149bace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_2 = (np.cos(2*np.pi*x/(0.5*nx) + 0.5*nx) + np.cos(2*np.pi*y/(0.5*ny) + 0.5*ny)) * np.sin(2*np.pi*t/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b42e4-029c-4f90-a4c4-841f8867d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(x[:, :, 2], y[:, :, 2], mode_2[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar()\n",
    "plt.ylabel('$y$')\n",
    "plt.xlabel('$x$')\n",
    "plt.title('Mode 2 at $t=0$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f518f-7fd4-453a-9a11-6ce91a5f3b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(t[0, :, :], y[0, :, :], mode_2.mean(axis=0), cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar()\n",
    "plt.ylabel('$y$')\n",
    "plt.xlabel('$t$')\n",
    "plt.title('Mode 2 zonal mean over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cdc74b-bb94-4714-a118-3b57049d839f",
   "metadata": {},
   "source": [
    "Now, let's add the modes together to get our full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd6def-a4fb-4688-889b-0b7a6df6b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mode_1 + mode_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad43b64-2cfb-4a77-b10e-f6359d1b930d",
   "metadata": {},
   "source": [
    "Visualize at $t=0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce0725-8dd7-4ea8-9d1c-66999f59b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(x[:, :, 2], y[:, :, 2], data[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar()\n",
    "plt.ylabel('$y$')\n",
    "plt.xlabel('$x$')\n",
    "plt.title('Data at $t=0$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb3021-b863-4d6d-9919-1e1f5f7d4675",
   "metadata": {},
   "source": [
    "## Prepare data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1497690-79ec-4da1-80f0-337d598222dc",
   "metadata": {},
   "source": [
    "You can see that the modes of variability have mixed, just like in real geophysical data. The next step is to take the time-mean out of every location. Since we just constructed the data and know its dimensions, we know time is `axis=2`. We also have to reshape the data before subtracting for the array broadcasting to work properly (we are trying subtracting an array of shape [10, 20] from an array of shape [10, 20, 50], but we need [10, 20] to be the final dimensions; with labeled Xarray data this would be simpler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf36fde1-3cf9-4a4e-9840-bf1ea243b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (data.reshape(50, 10, 20) - data.mean(axis=2)).reshape(10, 20, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e7af0-a81c-45ac-a36e-841cd8d6d3e4",
   "metadata": {},
   "source": [
    "The data then needs to be in the shape (space, time), so we stack the spatial dimensions $x,y$ into one dimension $s$. Knowing the size of $x$ and $y$ gives us the size of $s$: $10\\times20=200$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85834c-e3c0-407d-a379-f8ec8014908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2d = data.reshape(200, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15e9a5-8a6b-4308-a4b0-c8472fd55f11",
   "metadata": {},
   "source": [
    "## Do the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf71cc-2122-4cee-96d4-90aabe3e4f40",
   "metadata": {},
   "source": [
    "First, compute the covariance matrix $R$ of the 2-dimensional data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c85ff-41f0-4bb4-96d5-0eb5b94be27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.cov(data_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3a5bb-1e11-4fbe-9e20-2ec7f53bcb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea426b1a-2eb1-48a8-9982-171eec89ba0b",
   "metadata": {},
   "source": [
    "Now, we use `numpy.linalg.eig()` to find the eigenvalues `eigval` and eigenvectors `eigvec` of $R$. The eigenvectors will give us the EOFs and PCs, while the eigenvalues tell us about the variance explained by the corresponding eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b35dc-d1e0-498f-8b40-3c578e44ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(eigval, eigvec) = np.linalg.eig(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b280d-ed21-4d4f-bcbc-808b6f92216c",
   "metadata": {},
   "source": [
    "The eigenpairs are by default not sorted. We want to sort by the eigenvalues, since they tell us how important the eigenvectors are. Here, we first create an index `i` that can sort an array by the eigenvalues `eigval`. Then we sort both `eigval` and `eigvec`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6040fe8-ad2d-4f7c-ad11-be0286753191",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.argsort(-eigval)\n",
    "eigval = -np.sort(-eigval)\n",
    "eigvec = eigvec[:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71b1954-a351-4229-a71c-b195b5902664",
   "metadata": {},
   "source": [
    "The eigendecomposition resulted in 200 eigenpairs, which is the size of $s$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a486db2-e796-472b-8c64-4297bdc5ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigval.shape, eigvec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc9306-3151-4c20-909d-6bd6f5791438",
   "metadata": {},
   "source": [
    "Not all of these modes will be important. There are more objective ways to find out how many we should keep, but for now, we will just look at the eigenvalues and look for any clear separation or \"drop-off\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60211df6-4b1b-4e14-98bc-76240c8e4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(10), np.real(eigval[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2dfd5f-57c1-4e11-a163-cbece9639c7f",
   "metadata": {},
   "source": [
    "There is a pretty clear drop-off after the second eigenvalue, but let's keep the first four to see the difference. And before truncating, we will sum over the eigenvalues for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bafcc-b88e-45c4-991b-dcffb11ff836",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigval_sum = np.real(np.sum(eigval))\n",
    "\n",
    "r = 4\n",
    "eigval = eigval[:r]\n",
    "eigvec = eigvec[:, :r]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e402d30-b8d3-4401-b3c0-e7998980fecd",
   "metadata": {},
   "source": [
    "To transform the eigenvalues into _explained variance_, we need to divide by the sum of all eigenvalues and optionally multiply by 100 to get percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb35231-a8cc-4379-b749-2a94692fa928",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvar = np.real(eigval/eigval_sum*100)\n",
    "pvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99039d9-164d-43b4-b6c8-5efa3fe541db",
   "metadata": {},
   "source": [
    "Note that we could have also divided by the trace of $R$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1268fd-9c8b-4396-ab09-6575acb34e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.real(eigval/np.trace(R)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0259e-a053-43d2-beed-5b25f7518d98",
   "metadata": {},
   "source": [
    "To get the PCs, we multiply the 2-dimensional data by the eigenvectors. Looking at the shape of the arrays can help us figure out if we need to transpose (`.T`) anything. What shape do we expect the PC data to have? There are four of them with 50 time steps each, so (4, 50) or (50, 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d55ab-c27e-4582-82e7-6dd602af40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2d.shape, eigvec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cfdfac-ac84-416a-be84-b9ecab312ce1",
   "metadata": {},
   "source": [
    "We need to transpose the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22562ff-6ecb-4afd-a108-b345b03ea64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = np.real(np.dot(data_2d.T, eigvec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d88cd-26d7-4f7e-a26a-0d0ad957d3dd",
   "metadata": {},
   "source": [
    "The PCs have dimensions (time, mode):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce15b7e-57de-4863-97a0-99a0f24a5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb9da04-bb59-46d9-869f-9111dc87cb6c",
   "metadata": {},
   "source": [
    "Lets look at the PCs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c015bc-a5ed-4c09-94e9-d31aa756553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pcs[:, 0], label='PC1')\n",
    "plt.plot(pcs[:, 1], label='PC2')\n",
    "plt.plot(pcs[:, 2], label='PC3', linestyle=':')\n",
    "plt.plot(pcs[:, 3], label='PC4', linestyle=':')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylabel('PC')\n",
    "plt.xlabel('$t$')\n",
    "plt.xlim(0, nt-1)\n",
    "plt.title('First four PCs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e11b4-6e23-4ce3-a3a4-f768f6c4fa2e",
   "metadata": {},
   "source": [
    "The EOFs are just the eigenvectors, but we need to reshape them back into the two spatial dimensions $x,y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278cd4ea-94bb-4512-830d-830db8f0607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eofs = np.real(eigvec.reshape(10, 20, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02fe28-8c02-4e85-a3a4-e5a7714a405a",
   "metadata": {},
   "source": [
    "Let's look at the leading EOF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a798cca-aa5d-4718-8287-a8421f02fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(x[:, :, 0], y[:, :, 0], eofs[:, :, 0], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar()\n",
    "plt.ylabel('$y$')\n",
    "plt.xlabel('$x$')\n",
    "plt.title('EOF1 (%.1f%%)' %pvar[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb14022-4c6e-4381-869f-aae5d13053fa",
   "metadata": {},
   "source": [
    "This looks like Mode 2 but with opposite sign and lower magnitude. We can attempt to reconstruct Mode 2 by multiplying this EOF with the corresponding PC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e54505-e313-410c-aa03-606a3ba86749",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "mode_2_reco_plot = ax[0].pcolormesh(x[:, :, 0], y[:, :, 0], eofs[:, :, 0]*pcs[2, 0], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar(mode_2_reco_plot, ax=ax[0])\n",
    "ax[0].set_ylabel('$y$')\n",
    "ax[0].set_xlabel('$x$')\n",
    "ax[0].set_title('Reconstructed Mode 2 at $t=0$')\n",
    "\n",
    "mode_2_orig_plot = plt.pcolormesh(x[:, :, 2], y[:, :, 2], mode_2[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar(mode_2_orig_plot, ax=ax[1])\n",
    "ax[1].set_ylabel('$y$')\n",
    "ax[1].set_xlabel('$x$')\n",
    "ax[1].set_title('Original Mode 2 at $t=0$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5fb287-4395-4ca7-bef2-a89f04cb0e79",
   "metadata": {},
   "source": [
    "Here is the next EOF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222eba6-359a-4f2b-b6be-96014c34a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(x[:, :, 0], y[:, :, 0], eofs[:, :, 1], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar()\n",
    "plt.ylabel('$y$')\n",
    "plt.xlabel('$x$')\n",
    "plt.title('EOF2 (%.1f%%)' %pvar[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8835956-eaf2-4df2-a4af-9ab2c26e91c5",
   "metadata": {},
   "source": [
    "This is Mode 1, plus some noise and some apparent contamination (_mode mixing_) from Mode 2. We could reconstruct this mode, as well, but instead, let's take a look at the next two modes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81651496-6666-48c6-8419-c5588ca08434",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(x[:, :, 0], y[:, :, 0], eofs[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar()\n",
    "plt.ylabel('$y$')\n",
    "plt.xlabel('$x$')\n",
    "plt.title('EOF3 (%.1f%%)' %pvar[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9d91c-130d-4540-8c29-de6c61d22069",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(x[:, :, 0], y[:, :, 0], eofs[:, :, 3], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar()\n",
    "plt.ylabel('$y$')\n",
    "plt.xlabel('$x$')\n",
    "plt.title('EOF4 (%.1f%%)' %pvar[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c60100-3f24-458a-a7b2-9d3b38b590e2",
   "metadata": {},
   "source": [
    "EOF3 looks like some sort of residual from Mode 1, while EOF4 shows some zonal stripes that were not in our original data. Even though there is structure here, we should not interpret these as a meaningful or _physical_ modes of variability in the data; they are artifacts of the method, particularly the orthogonality constraints. The very low explained variance is also an indication that the modes are probably not meaningful. \n",
    "\n",
    "PC3 shows an oscillation with a period of about 10 time steps and EOF3 shows a pattern that we might expect from the data, so if we didn't have _a priori_ knowledge about the data, we might have been tempted to interpret this mode as meaningful. We therefore have to be careful when interpreting the modes we find with EOF analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d61e973-7a02-482e-bccc-504782d0e690",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Change the period of Mode 2 from 15 time steps to 20 time steps, bringing it closer in frequency to Mode 1. What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c00cea-1826-43e8-bb1b-45b03af7bf4c",
   "metadata": {},
   "source": [
    "## Adding noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ca5ea-95f9-476d-90a0-8d51862bb63c",
   "metadata": {},
   "source": [
    "Real geophysical data is rarely so clean. Let's add some noise with a similar amplitude to the modes and see what happens. If the modes we constructed were modes of climate variability, this noise would be weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dbe76-a0d1-44bf-b45b-33a4706aaf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data = mode_1 + mode_2 + np.random.default_rng().normal(loc=0.0, scale=1.0, size=(nx, ny, nt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff05c2-2ce6-426d-98bb-129c05266504",
   "metadata": {},
   "source": [
    "Let's look at the data at $t=0$ for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40917cf8-b1a0-4ba4-9e23-db1343151b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(x[:, :, 2], y[:, :, 2], noisy_data[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar()\n",
    "plt.ylabel('$y$')\n",
    "plt.xlabel('$x$')\n",
    "plt.title('Noisy data at $t=0$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebd6e3-f407-44fd-b2a9-75785f8c0796",
   "metadata": {},
   "source": [
    "The modes aren't nearly as apparent with the noise added, just like real climate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5d03c-2ded-483b-b98e-c6308db7e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data = (noisy_data.reshape(50, 10, 20) - noisy_data.mean(axis=2)).reshape(10, 20, 50)\n",
    "noisy_data_2d = noisy_data.reshape(200, 50)\n",
    "\n",
    "n_R = np.cov(noisy_data_2d)\n",
    "(n_eigval, n_eigvec) = np.linalg.eig(n_R)\n",
    "\n",
    "n_i = np.argsort(-n_eigval)\n",
    "n_eigval = -np.sort(-n_eigval)\n",
    "n_eigvec = n_eigvec[:,i]\n",
    "r = 4\n",
    "n_eigval = n_eigval[:r]\n",
    "n_eigvec = n_eigvec[:, :r]\n",
    "\n",
    "n_pvar = np.real(n_eigval/np.trace(n_R)*100)\n",
    "n_pcs = np.real(np.dot(noisy_data_2d.T, n_eigvec))\n",
    "n_eofs = np.real(n_eigvec.reshape(10, 20, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41f38e1-d56e-4c49-9e79-6c8bc8f7177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_pcs[:, 0], label='PC1')\n",
    "plt.plot(n_pcs[:, 1], label='PC2')\n",
    "plt.plot(n_pcs[:, 2], label='PC3', linestyle=':')\n",
    "plt.plot(n_pcs[:, 3], label='PC4', linestyle=':')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylabel('PC')\n",
    "plt.xlabel('$t$')\n",
    "plt.xlim(0, nt-1)\n",
    "plt.title('First four PCs (noisy data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da38763-c786-48cc-8671-b6452264e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fig, n_ax = plt.subplots(2, 2, figsize=(10, 5), layout='constrained')\n",
    "\n",
    "noisy_eof1_plot = n_ax[0, 0].pcolormesh(x[:, :, 0], y[:, :, 0], n_eofs[:, :, 0], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar(noisy_eof1_plot, ax=n_ax[0, 0])\n",
    "n_ax[0, 0].set_ylabel('$y$')\n",
    "n_ax[0, 0].set_title('Noisy EOF1 (%.1f%%)' %n_pvar[0])\n",
    "\n",
    "noisy_eof2_plot = n_ax[0, 1].pcolormesh(x[:, :, 0], y[:, :, 0], n_eofs[:, :, 1], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar(noisy_eof1_plot, ax=n_ax[0, 1])\n",
    "n_ax[0, 1].set_title('Noisy EOF2 (%.1f%%)' %n_pvar[1])\n",
    "\n",
    "noisy_eof3_plot = n_ax[1, 0].pcolormesh(x[:, :, 0], y[:, :, 0], n_eofs[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar(noisy_eof3_plot, ax=n_ax[1, 0])\n",
    "n_ax[1, 0].set_ylabel('$y$')\n",
    "n_ax[1, 0].set_xlabel('$x$')\n",
    "n_ax[1, 0].set_title('Noisy EOF3 (%.1f%%)' %n_pvar[2])\n",
    "\n",
    "noisy_eof4_plot = n_ax[1, 1].pcolormesh(x[:, :, 0], y[:, :, 0], n_eofs[:, :, 3], cmap='RdBu_r', norm=CenteredNorm())\n",
    "plt.colorbar(noisy_eof4_plot, ax=n_ax[1, 1])\n",
    "n_ax[1, 1].set_xlabel('$x$')\n",
    "n_ax[1, 1].set_title('Noisy EOF4 (%.1f%%)' %n_pvar[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9668721a-542c-4b7b-a2f8-54a474517f7f",
   "metadata": {},
   "source": [
    "The EOF analysis has again successfully identified our two modes. The third and fourth modes explain more variance than in the clean example, but the spatial patterns strongly suggest that they are just noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f68ea-ce77-44df-9a3d-da4d3142e4b3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f3d42-6bbc-43dc-9715-31922777e613",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, we implemented the EOF method on some synthetic data using NumPy. First, we generated two simple modes of variability and combined them. Then, our EOF analysis was able to largely isolate the modes as the first two EOF/PC pairs.\n",
    "\n",
    "### What's next?\n",
    "In the next notebook, we will use a package called [xeofs](https://xeofs.readthedocs.io/) to find climate modes in real sea surface temperature data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

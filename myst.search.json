{"version":"1","records":[{"hierarchy":{"lvl1":"EOFs Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"EOFs Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nThis Project Pythia Cookbook covers empirical orthogonal function analysis and its application to climate data.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl2":"Motivation"},"content":"Empirical orthogonal function (EOF) analysis is an essential tool for studying the variability of the atmosphere–ocean system. Meteorological and oceanographic data is noisy and multidimensional, but an EOF analysis allows us to pull out patterns from the data that might otherwise be difficult to find. The goal of this cookbook is to provide background and context to the analysis alongside practical examples of carrying out the analysis using Python packages.","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl2":"Authors"},"content":"Robert Ford","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl2":"Structure"},"content":"This cookbook currently has one section that covers the basics of EOF analysis.","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl3":"Foundations","lvl2":"Structure"},"type":"lvl3","url":"/#foundations","position":10},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl3":"Foundations","lvl2":"Structure"},"content":"This section includes three notebooks:\n\nIntroduction to EOFs\n\nEOFs with NumPy\n\nFinding Climate Modes with EOFs","type":"content","url":"/#foundations","position":11},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":12},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":13},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":14},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.","type":"content","url":"/#running-on-binder","position":15},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":16},{"hierarchy":{"lvl1":"EOFs Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/eofs-cookbook repository: git clone https://github.com/ProjectPythia/eofs-cookbook.git\n\nMove into the eofs-cookbook directorycd eofs-cookbook\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate eofs-cookbook-dev\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":17},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs"},"type":"lvl1","url":"/notebooks/climate-modes-xeofs","position":0},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs"},"content":"\n\n","type":"content","url":"/notebooks/climate-modes-xeofs","position":1},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/climate-modes-xeofs#overview","position":2},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Overview"},"content":"In this notebook, we will identify and plot a few different modes of climate variability with the help of an EOF package that interfaces with Xarray called \n\nxeofs.\n\n","type":"content","url":"/notebooks/climate-modes-xeofs#overview","position":3},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/climate-modes-xeofs#prerequisites","position":4},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Xarray\n\nNecessary\n\n\n\nIntro to EOFs\n\nHelpful\n\n\n\nEOFs with NumPy\n\nHelpful\n\n\n\nTime to learn: 30 minutes\n\n\n\n","type":"content","url":"/notebooks/climate-modes-xeofs#prerequisites","position":5},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/climate-modes-xeofs#imports","position":6},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Imports"},"content":"\n\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\nimport xeofs as xe\n\n","type":"content","url":"/notebooks/climate-modes-xeofs#imports","position":7},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Accessing and preparing the data"},"type":"lvl2","url":"/notebooks/climate-modes-xeofs#accessing-and-preparing-the-data","position":8},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Accessing and preparing the data"},"content":"\n\nWe will use the \n\nNOAA Extended Reconstructed Sea Surface Temperature version 5 (ERSSTv5) monthly gridded dataset \n\nHuang et al., 2017, which is accessible using \n\nOPeNDAP. More information on \n\nusing OPeNDAP to access NOAA data can be found here.\n\ndata_url = 'https://psl.noaa.gov/thredds/dodsC/Datasets/noaa.ersst.v5/sst.mnmean.nc'\n\nsst = xr.open_dataset(data_url).sst\nsst\n\nCheck that the data looks as expected:\n\nsst.isel(time=0).plot()\n\nBefore we modify the data, let’s do an EOF analysis on the whole dataset:\n\ns_model = xe.single.EOF(n_modes=4, use_coslat=True)\ns_model.fit(sst, dim='time')\ns_eofs = s_model.components()\ns_pcs = s_model.scores()\ns_expvar = s_model.explained_variance_ratio()\n\ns_eofs.plot(col='mode')\n\ns_pcs.plot(col='mode')\n\ns_expvar\n\nEOF1 explains 83% of the variance, and the map shows interhemispheric asymmetry. The corresponding PC has a period of one year, which we can see more clearly by only plotting a few years:\n\ns_pcs.sel(mode=1, time=slice('1900', '1903')).plot(figsize=(8, 3))\n\nThis mode is showing the seasonal cycle. This is interesting, but it obfuscates other modes. If we want to study the other ways Earth’s climate varies, we should remove the seasonal cycle from our data. Here we compute this (calling it the SST anomaly) by subtracting out the average of each month using Xarray’s .groupby() method:\n\nsst_clim = sst.groupby('time.month')\nssta = sst_clim - sst_clim.mean(dim='time')\n\nThe remaining 3 EOFs show a combination of the long-term warming trend, the seasonal cycle (EOF analyses do not cleanly separate physical modes), and other internal variability. The warming trend is also interesting (see the \n\nCMIP6 Cookbook), but here we want to pull out some modes of internal/natural variability. We can detrend the data by removing the global average SST anomaly.\n\ndef global_average(data):\n    weights = np.cos(np.deg2rad(data.lat))\n    data_weighted = data.weighted(weights)\n    return data_weighted.mean(dim=['lat', 'lon'], skipna=True)\n\nssta_dt = (ssta - global_average(ssta)).squeeze()\n\nLet’s find the global EOFs again but with the deseasonalized, detrended data:\n\nds_model = xe.single.EOF(n_modes=4, use_coslat=True)\nds_model.fit(ssta_dt, dim='time')\nds_eofs = ds_model.components()\nds_pcs = ds_model.scores()\nds_expvar = ds_model.explained_variance_ratio()\n\nds_eofs.plot(col='mode')\n\nds_pcs.plot(col='mode')\n\nds_expvar\n\nNow we can see some modes of variability! EOF1 looks like ENSO or IPO, and EOF2 is probably picking up a pattern of the recent temperature trend where the Southern Ocean and southeastern Pacific are slightly cooling. EOF3 and EOF4 appear to be showing some decadal modes of variability (PDO and maybe AMO), among other things. There is a lot going on in each of these maps, so to get a clearer index of some modes, we can restrict our domain.\n\n","type":"content","url":"/notebooks/climate-modes-xeofs#accessing-and-preparing-the-data","position":9},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"El Niño Southern Oscillation (ENSO)"},"type":"lvl2","url":"/notebooks/climate-modes-xeofs#el-ni-o-southern-oscillation-enso","position":10},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"El Niño Southern Oscillation (ENSO)"},"content":"Here we restrict our domain to the equatorial Pacific. Note that ENSO is commonly defined using an index of SST anomaly over a region of the equatorial Pacific (e.g., the \n\nOceanic Niño Index (ONI)) instead of an EOF. You can \n\nread more about ENSO here.\n\nep_ssta_dt = ssta_dt.where((ssta_dt.lat < 30) & (ssta_dt.lat > -30) & (ssta_dt.lon > 120) & (ssta_dt.lon < 290), drop=True)\n\nep_model = xe.single.EOF(n_modes=4, use_coslat=True)\nep_model.fit(ep_ssta_dt, dim='time')\nep_eofs = ep_model.components()\nep_pcs = ep_model.scores()\nep_expvar = ep_model.explained_variance_ratio()\n\nep_eofs.plot(col='mode')\n\nep_pcs.plot(col='mode')\n\nep_expvar\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 2), dpi=130)\nplt.fill_between(ep_pcs.time, ep_pcs.isel(mode=0).where(ep_pcs.isel(mode=0) > 0), color='r')\nplt.fill_between(ep_pcs.time, ep_pcs.isel(mode=0).where(ep_pcs.isel(mode=0) < 0), color='b')\nplt.ylabel('PC')\nplt.xlabel('Year')\nplt.xlim(ep_pcs.time.min(), ep_pcs.time.max())\nplt.grid(linestyle=':')\nplt.title('ENSO Index (detrended equatorial Pacific SSTA EOF1)')\n\nCompare to the ONI:\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 2), dpi=130)\nplt.fill_between(ep_pcs.time, ep_pcs.isel(mode=0).where(ep_pcs.isel(mode=0) > 0), color='r')\nplt.fill_between(ep_pcs.time, ep_pcs.isel(mode=0).where(ep_pcs.isel(mode=0) < 0), color='b')\nplt.ylabel('PC')\nplt.xlabel('Year')\nplt.xlim(ep_pcs.time.sel(time='1950-01').squeeze(), ep_pcs.time.max())\nplt.grid(linestyle=':')\nplt.title('ENSO Index (detrended equatorial Pacific SSTA EOF1)')\n\n\n\n","type":"content","url":"/notebooks/climate-modes-xeofs#el-ni-o-southern-oscillation-enso","position":11},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Pacific Decadal Oscillation (PDO)"},"type":"lvl2","url":"/notebooks/climate-modes-xeofs#pacific-decadal-oscillation-pdo","position":12},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Pacific Decadal Oscillation (PDO)"},"content":"Here we restrict our domain to the North Pacific. You can \n\nread more about PDO here.\n\nnp_ssta_dt = ssta_dt.where((ssta_dt.lat < 70) & (ssta_dt.lat > 20) & (ssta_dt.lon > 120) & (ssta_dt.lon < 260), drop=True)\n\nnp_model = xe.single.EOF(n_modes=4, use_coslat=True)\nnp_model.fit(np_ssta_dt, dim='time')\nnp_eofs = np_model.components()\nnp_pcs = np_model.scores()\nnp_expvar = np_model.explained_variance_ratio()\n\nnp_eofs.plot(col='mode')\n\nnp_pcs.plot(col='mode')\n\nnp_expvar\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 2), dpi=130)\nplt.fill_between(np_pcs.time, np_pcs.isel(mode=0).where(np_pcs.isel(mode=0) > 0), color='r')\nplt.fill_between(np_pcs.time, np_pcs.isel(mode=0).where(np_pcs.isel(mode=0) < 0), color='b')\nplt.plot(np_pcs.time, np_pcs.isel(mode=0).rolling(time=48, center=True).mean(), color='k', linewidth=2)\nplt.ylabel('PC')\nplt.xlabel('Year')\nplt.xlim(np_pcs.time.min(), np_pcs.time.max())\nplt.grid(linestyle=':')\nplt.title('PDO Index (detrended North Pacific SSTA EOF1)')\n\n\n\n","type":"content","url":"/notebooks/climate-modes-xeofs#pacific-decadal-oscillation-pdo","position":13},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/climate-modes-xeofs#summary","position":14},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Summary"},"content":"In this notebook, we demonstrated a basic workflow for performing an EOF analysis on gridded SST data using the xeofs package. We plotted the PCs associated with ENSO and PDO using deseasonalized, detrended SSTs.","type":"content","url":"/notebooks/climate-modes-xeofs#summary","position":15},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/climate-modes-xeofs#whats-next","position":16},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl3":"What’s next?","lvl2":"Summary"},"content":"In the future, additional notebooks may use EOFs to recreate published figures, give an overview of other EOF packages, or explore variations of the EOF method.\n\n","type":"content","url":"/notebooks/climate-modes-xeofs#whats-next","position":17},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/climate-modes-xeofs#resources-and-references","position":18},{"hierarchy":{"lvl1":"Finding Climate Modes with EOFs","lvl2":"Resources and references"},"content":"Scientific description of the ERSSTv5 data set: \n\nHuang et al. (2017), doi:10.1175/jcli-d-16-0836.1\n\nxeofs documentation\n\nPaper describing the xeofs software: \n\nRieger et al., (2024) doi:10.21105/joss.06060","type":"content","url":"/notebooks/climate-modes-xeofs#resources-and-references","position":19},{"hierarchy":{"lvl1":"Introduction to EOFs"},"type":"lvl1","url":"/notebooks/eof-intro","position":0},{"hierarchy":{"lvl1":"Introduction to EOFs"},"content":"\n\n","type":"content","url":"/notebooks/eof-intro","position":1},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/eof-intro#overview","position":2},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Overview"},"content":"In this notebook, we will provide some background on empirical orthogonal functions (EOFs), develop some intuition, and cover the relevant mathematics.\n\n","type":"content","url":"/notebooks/eof-intro#overview","position":3},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/eof-intro#prerequisites","position":4},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nLinear algebra\n\nNecessary\n\n\n\nTime to learn: 20 minutes\n\n\n\n","type":"content","url":"/notebooks/eof-intro#prerequisites","position":5},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/eof-intro#imports","position":6},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Imports"},"content":"\n\nN/A\n\n","type":"content","url":"/notebooks/eof-intro#imports","position":7},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Introduction"},"type":"lvl2","url":"/notebooks/eof-intro#introduction","position":8},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Introduction"},"content":"EOFs are commonly used to study the spatial and temporal variability of geophysical fields like sea surface temperature, sea level pressure, or geopotential height. Similar to how Fourier analysis allows us to decompose a time series into a sum of sinusoids of different frequencies, EOF analysis allows us to decompose a geophysical field into a set of mutually orthogonal spatial patterns and corresponding time series that are determined by the data (so, empirically). Terminology varies across texts, but here we will refer to the spatial patterns as “EOFs” and the time series as the “principal components” (PCs).\n\nEach EOF-PC pair can be thought of as a mode of variability in the data, but it is not necessary that these modes represent something physical. Each mode comes with a corresponding variance fraction that tells us how important the mode is. This is often phrased something like “the first mode explains 25% of the variance in the data,” and we will discuss what this means mathematically in the following sections. If a mode explains a large fraction of the total variance, it is more likely to be capturing some physical mode of variability, like the \n\nEl Niño Southern Oscillation (ENSO) or \n\nNorth Atlantic Oscillation (NAO).\n\n","type":"content","url":"/notebooks/eof-intro#introduction","position":9},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Examples of use"},"type":"lvl2","url":"/notebooks/eof-intro#examples-of-use","position":10},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Examples of use"},"content":"EOF analysis (also called principal component analysis, PCA) has been applied to meteorological and oceanographic data since the 1940s and 1970s, respectively \n\nPreisendorfer & Mobley, 1988. Here are a few examples of its use:","type":"content","url":"/notebooks/eof-intro#examples-of-use","position":11},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl3":"Identifying climate modes: the Pacific Decadal Oscillation","lvl2":"Examples of use"},"type":"lvl3","url":"/notebooks/eof-intro#identifying-climate-modes-the-pacific-decadal-oscillation","position":12},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl3":"Identifying climate modes: the Pacific Decadal Oscillation","lvl2":"Examples of use"},"content":"The Pacific Decadal Oscillation (PDO) is a mode of climate variability characterized by decadal-scale sea surface temperature (SST) anomalies in the North Pacific. As typically defined, the positive/warm phase of PDO occurs when the SSTs off the west coast of North America are anomalously warm and the eastern/interior North Pacific is anomalously cold (and vice versa for the negative/cold phase). Since its identification and naming in the 1990s, PDO has been defined as the leading (i.e., first) EOF in North Pacific SST anomalies \n\nMantua & Hare, 2002. This is the same definition used by \n\nNOAA in their PDO index.\n\n\n\nAdapted from \n\nMantua & Hare (2002). The three plots on the top show the EOFs for SST, sea level pressure, and surface wind stress, while the time series at the bottom is the associated PC.\n\nBesides the modes of variability already mentioned, an EOF analysis can also be used to identify the Northern and Southern Annular Modes (NAM and SAM), the Atlantic Multidecadal Oscillation/Variability (AMO/V), the zonal wave 3 pattern (ZW3) of both hemispheres, and others.","type":"content","url":"/notebooks/eof-intro#identifying-climate-modes-the-pacific-decadal-oscillation","position":13},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl3":"Identifying patterns across an ensemble","lvl2":"Examples of use"},"type":"lvl3","url":"/notebooks/eof-intro#identifying-patterns-across-an-ensemble","position":14},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl3":"Identifying patterns across an ensemble","lvl2":"Examples of use"},"content":"While an EOF analysis is usually applied to data that is a function of space and time, it can also be used with data that is a function of space and ensemble member. Then the analysis may be able to identify the most important patterns that characterize the differences between ensemble members. \n\nTokinaga et al. (2012) perform an EOF analysis on an ensemble of 100 realizations of observed SSTs in order to understand the uncertainty in the zonal SST gradient in the tropical Pacific.\n\n\n\nAdapted from \n\nTokinaga et al. (2012). The left plot shows the leading EOF (with 83.6% variance fraction) of tropical Pacific SST across 100 realizations of observed SSTs. The right plot shows the PC (in this case, a single value instead of a time series) associated with the EOF plotted against the zonal SST gradient in the tropical Pacific for each ensemble member.","type":"content","url":"/notebooks/eof-intro#identifying-patterns-across-an-ensemble","position":15},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl3":"Isolating the global warming signal","lvl2":"Examples of use"},"type":"lvl3","url":"/notebooks/eof-intro#isolating-the-global-warming-signal","position":16},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl3":"Isolating the global warming signal","lvl2":"Examples of use"},"content":"To isolate the global warming signal from internal variability, it is common to run a climate model multiple times—with the same anthropogenic emissions and slightly different initial conditions—and take the average response across the ensemble. With enough ensemble members, the internal variability should mostly cancel out, identifying the ensemble average with the model’s response to the emissions. Unfortunately, we cannot use this method on Earth’s actual climate, which only has one realization. As you will see in \n\nFinding Climate Modes with EOFs, the long-term warming trend will be apparent in an EOF analysis of observed SSTs if the data is not detrended, but it is not cleanly separated from internal variability. \n\nWills et al. (2018) develop a method, which they call low-frequency component analysis (LFCA), that can more cleanly separate out the warming trend. After perfoming an EOF analysis, their method finds a linear combination of the EOFs that maximizes the variance fraction at low frequencies (see their paper for more details).\n\n\n\nAdapted from \n\nWills et al. (2018). Three leading low frequency patterns (LFPs, similar to EOFs) and their corresponding low frequency components (LFCs, similar to PCs) for Pacific SST anomalies. This method is able to separate the global warming trend from PDO and ENSO.\n\n","type":"content","url":"/notebooks/eof-intro#isolating-the-global-warming-signal","position":17},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"The method"},"type":"lvl2","url":"/notebooks/eof-intro#the-method","position":18},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"The method"},"content":"The steps required to compute EOFs and PCs are as follows:\n\nOrganize your data into a 2-dimensional matrix \\mathbf F and remove the mean from each time series\n\nCalculate the covariance matrix \\mathbf R=\\mathbf F\\mathbf F^\\mathrm T\n\nFind the eigenvectors (EOFs) \\mathbf e_m\\in\\mathbf E and eigenvalues \\lambda_m\\in\\mathbf\\Lambda of \\mathbf R by solving \\mathbf R\\mathbf E=\\mathbf\\Lambda\\mathbf E\n\nOrder the eigenvectors by their eigenvalues, since the eigenvalues are proportional to the fraction of variance explained by that mode\n\nCalculate the PCs for each mode with \\mathbf c_m=\\mathbf e_m^\\mathrm T\\cdot\\mathbf F (i.e. projecting your data onto each eigenvector/EOF)\n\nFind the variance fraction for each mode with \\lambda_m\\Large/\\normalsize\\sum_i^M\\lambda_i\n\n","type":"content","url":"/notebooks/eof-intro#the-method","position":19},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Bonus: deriving the eigenvalue problem"},"type":"lvl2","url":"/notebooks/eof-intro#bonus-deriving-the-eigenvalue-problem","position":20},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Bonus: deriving the eigenvalue problem"},"content":"As an aside, it is not obvious why solving the eigenvalue problem for the covariance matrix results in spatial patterns that align well with the data. The following explanation follows those given by \n\nPreisendorfer & Mobley (1988), \n\nPeixoto & Oort (1992), and \n\nBjörnsson & Venegas (1997).\n\nLet f(x, t) be a geophysical field recorded over locations x_1, x_2, \\dots, x_M and times t_1, t_2, \\dots, t_N. In matrix notation, we can write each map of M locations as the column vector \\mathbf{f}_n=\\begin{bmatrix}f_{1n} & f_{2n} & \\cdots & f_{Mn}\\end{bmatrix}^\\mathrm T, where n=1, \\dots, N. We then have an M\\times N matrix that can be written as \\mathbf F=\\begin{bmatrix}\\mathbf{f}_1 & \\mathbf{f}_2 & \\cdots & \\mathbf{f}_N\\end{bmatrix}.\n\nNow, imagine that we only have three locations to collect data. Then each \\mathbf{f}_n would be a 3-dimensional vector, and the whole set could be represented as a linear combination of three arbitrary basis vectors. This generalizes such that the vector space \\mathbf F is spanned by an arbirary unit basis \\{\\mathbf u_1,\\mathbf u_2,\\dots,\\mathbf u_M\\}. It is very likely that some of the vectors \\mathbf f_n are correlated as a result of some physical process. The goal of the EOF analysis is then to find an orthogonal unit basis \\{\\mathbf e_1,\\mathbf e_2,\\dots,\\mathbf e_M\\} that aligns well with these vector “clusters”.\n\n\n\nAdapted from \n\nPeixoto & Oort (1992).\n\nThis is now an optimization problem. To maximize the alignment between the basis and observations, we will maximize the projection of the vectors \\mathbf f_n onto each basis vector using the sum of squares:\\sum_{n=1}^N(\\mathbf f_n \\cdot \\mathbf e_m)^2\n\nfor m=1, 2, \\dots, M. We also require mutual orthonormality for the basis: \\mathbf e_i\\cdot\\mathbf e_j=\\delta_{ij}. Now, let’s define this quantity as \\psi(\\mathbf e_m):\\begin{aligned}\n\\psi(\\mathbf e_m)\\equiv\\sum_{n=1}^N(\\mathbf f_n \\cdot \\mathbf e_m)^2\n&=\\sum_{n=1}^N(\\mathbf e_m^\\mathrm T \\mathbf f_n)(\\mathbf f_n^\\mathrm T\\mathbf e_m)\\\\\n&=\\mathbf e_m^\\mathrm T \\sum_{n=1}^N(\\mathbf f_n\\mathbf f_n^\\mathrm T\\mathbf) e_m\\\\\n&=\\mathbf e_m^\\mathrm T \\mathbf F\\mathbf F^\\mathrm T\\mathbf e_m\\\\\n&=\\mathbf e_m^\\mathrm T \\mathbf R\\mathbf e_m\n\\end{aligned}\n\nwhere \\mathbf R=\\mathbf F\\mathbf F^\\mathrm T is the covariance matrix of \\mathbf F.\n\nWe now seek the extrema of \\psi(\\mathbf e) (dropping the subscript m for convenience), which satisfy \\psi(\\mathbf e+\\delta\\mathbf e)=\\psi(\\mathbf e) for a small change \\delta\\mathbf e in the direction of \\mathbf e. Then\\begin{aligned}\n\\psi(\\mathbf e+\\delta\\mathbf e)&=(\\mathbf e+\\delta\\mathbf e)^\\mathrm T\\mathbf R(\\mathbf e+\\delta\\mathbf e)\\\\\n&=\\mathbf e^\\mathrm T\\mathbf R\\mathbf e+2(\\delta\\mathbf e)^\\mathrm T\\mathbf R\\mathbf e + (\\delta\\mathbf e)^\\mathrm T\\mathbf R\\delta\\mathbf e\\\\\n&\\approx\\mathbf e^\\mathrm T\\mathbf R\\mathbf e+2(\\delta\\mathbf e)^\\mathrm T\\mathbf R\\mathbf e\\\\\n&=\\psi(\\mathbf e)+2(\\delta\\mathbf e)^\\mathrm T\\mathbf R\\mathbf e\n\\end{aligned}\n\nwhere we only keep the terms first order in \\delta\\mathbf e. The optimization condition implies(\\delta\\mathbf e)^\\mathrm T\\mathbf R\\mathbf e=0\n\nBy the orthonormality of the basis, we also require that these variations only change the direction of \\mathbf e, so (\\mathbf e+\\delta\\mathbf e)^\\mathrm T(\\mathbf e+\\delta\\mathbf e)=1\\Rightarrow(\\delta\\mathbf e)^\\mathrm T\\mathbf e=0, again only keeping terms first order in \\delta\\mathbf e. We can combine these two conditions, provided that we multiply the orthonormality condition by a constant that has the same units as the entries of \\mathbf R:(\\delta\\mathbf e)^\\mathrm T\\mathbf R\\mathbf e-\\lambda(\\delta\\mathbf e)^\\mathrm T\\mathbf e=(\\delta\\mathbf e)^\\mathrm T[\\mathbf R\\mathbf e-\\lambda\\mathbf e]=0\n\nSince \\delta\\mathbf e is arbitrary, we must have \\mathbf R\\mathbf e-\\lambda\\mathbf e=0, the eigenvalue problem for \\mathbf R, or for nontrivial solutions, |\\mathbf R-\\lambda\\mathbf I|=0.\n\n\n\n","type":"content","url":"/notebooks/eof-intro#bonus-deriving-the-eigenvalue-problem","position":21},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/eof-intro#summary","position":22},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl2":"Summary"},"content":"In this notebook, we covered some background on EOFs, the steps required to carry out an EOF analysis, and some of the math behind the analysis.","type":"content","url":"/notebooks/eof-intro#summary","position":23},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/eof-intro#whats-next","position":24},{"hierarchy":{"lvl1":"Introduction to EOFs","lvl3":"What’s next?","lvl2":"Summary"},"content":"In the next notebook, we will implement the EOF method on some simple, synthetic data using NumPy.","type":"content","url":"/notebooks/eof-intro#whats-next","position":25},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in Project Pythia’s EOFs Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"EOFs with NumPy"},"type":"lvl1","url":"/notebooks/numpy-eofs","position":0},{"hierarchy":{"lvl1":"EOFs with NumPy"},"content":"\n\n","type":"content","url":"/notebooks/numpy-eofs","position":1},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/numpy-eofs#overview","position":2},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Overview"},"content":"In order to gain some familiarity with the method, this notebook will work through the EOF method step by step on some synthetic data. We will also see clearly some of the limitations of the method, including mode mixing \n\nChen et al., 2017 and the generation of unphysical modes \n\nDommenget & Latif, 2002.\n\n","type":"content","url":"/notebooks/numpy-eofs#overview","position":3},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/numpy-eofs#prerequisites","position":4},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nFoundations NumPy section\n\nNecessary\n\n\n\nIntro to EOFs\n\nHelpful\n\n\n\nTime to learn: 20 minutes\n\n\n\n","type":"content","url":"/notebooks/numpy-eofs#prerequisites","position":5},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/numpy-eofs#imports","position":6},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Imports"},"content":"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import CenteredNorm\n\n","type":"content","url":"/notebooks/numpy-eofs#imports","position":7},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Set the domain"},"type":"lvl2","url":"/notebooks/numpy-eofs#set-the-domain","position":8},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Set the domain"},"content":"Assume a domain with two spatial dimensions, x and y, and time t. For simplicity, we will start all dimensions at zero and increment by one up to some arbitrary maximum, here x=9, y=19, and t=49. Different dimension lengths will help highlight the shape of the data as we work through the EOF analysis. We are using numpy.mgrid to create our 3-dimensional domain.\n\nx, y, t = np.mgrid[0:10, 0:20, 0:50]\nnx, ny, nt = x.shape[0], x.shape[1], x.shape[2]\n\nx.shape\n\n","type":"content","url":"/notebooks/numpy-eofs#set-the-domain","position":9},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Generate some data"},"type":"lvl2","url":"/notebooks/numpy-eofs#generate-some-data","position":10},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Generate some data"},"content":"Let’s generate some “modes of variability” in the domain. We will combine them and then use an EOF analysis to pull them back apart. First, here is a 2-dimensional Gaussian that oscillates between positive and negative with a period of 25 time steps:\n\nmode_1 = 4*np.exp(-((x - np.mean(x))**2)/3 - ((y - np.mean(y))**2)/5) * np.cos(2*np.pi*t/25)\n\nplt.pcolormesh(x[:, :, 0], y[:, :, 0], mode_1[:, :, 0], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar()\nplt.ylabel('$y$')\nplt.xlabel('$x$')\nplt.title('Mode 1 at $t=0$')\n\nTo see how this mode changes over time, we can take the mean over the x-axis (a “zonal” mean), and plot it as a function of y and t:\n\nplt.pcolormesh(t[0, :, :], y[0, :, :], mode_1.mean(axis=0), cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar()\nplt.ylabel('$y$')\nplt.xlabel('$t$')\nplt.title('Mode 1 zonal mean over time')\n\nHere is a second mode, which is the sum of cosines in x and y and oscillates between positive and negative with a period of 15 time steps:\n\nmode_2 = (np.cos(2*np.pi*x/(0.5*nx) + 0.5*nx) + np.cos(2*np.pi*y/(0.5*ny) + 0.5*ny)) * np.sin(2*np.pi*t/15)\n\nplt.pcolormesh(x[:, :, 2], y[:, :, 2], mode_2[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar()\nplt.ylabel('$y$')\nplt.xlabel('$x$')\nplt.title('Mode 2 at $t=0$')\n\nplt.pcolormesh(t[0, :, :], y[0, :, :], mode_2.mean(axis=0), cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar()\nplt.ylabel('$y$')\nplt.xlabel('$t$')\nplt.title('Mode 2 zonal mean over time')\n\nNow, let’s add the modes together to get our full dataset:\n\ndata = mode_1 + mode_2\n\nVisualize at t=0:\n\nplt.pcolormesh(x[:, :, 2], y[:, :, 2], data[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar()\nplt.ylabel('$y$')\nplt.xlabel('$x$')\nplt.title('Data at $t=0$')\n\n","type":"content","url":"/notebooks/numpy-eofs#generate-some-data","position":11},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Prepare data for analysis"},"type":"lvl2","url":"/notebooks/numpy-eofs#prepare-data-for-analysis","position":12},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Prepare data for analysis"},"content":"\n\nYou can see that the modes of variability have mixed, just like in real geophysical data. The next step is to take the time-mean out of every location. Since we just constructed the data and know its dimensions, we know time is axis=2. We also have to reshape the data before subtracting for the array broadcasting to work properly (we are trying subtracting an array of shape [10, 20] from an array of shape [10, 20, 50], but we need [10, 20] to be the final dimensions; with labeled Xarray data this would be simpler).\n\ndata = (data.reshape(50, 10, 20) - data.mean(axis=2)).reshape(10, 20, 50)\n\nThe data then needs to be in the shape (space, time), so we stack the spatial dimensions x,y into one dimension s. Knowing the size of x and y gives us the size of s: 10\\times20=200:\n\ndata_2d = data.reshape(200, 50)\n\n","type":"content","url":"/notebooks/numpy-eofs#prepare-data-for-analysis","position":13},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Do the analysis"},"type":"lvl2","url":"/notebooks/numpy-eofs#do-the-analysis","position":14},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Do the analysis"},"content":"\n\nFirst, compute the covariance matrix R of the 2-dimensional data:\n\nR = np.cov(data_2d)\n\nR.shape\n\nNow, we use numpy.linalg.eig() to find the eigenvalues eigval and eigenvectors eigvec of R. The eigenvectors will give us the EOFs and PCs, while the eigenvalues tell us about the variance explained by the corresponding eigenvectors.\n\n(eigval, eigvec) = np.linalg.eig(R)\n\nThe eigenpairs are by default not sorted. We want to sort by the eigenvalues, since they tell us how important the eigenvectors are. Here, we first create an index i that can sort an array by the eigenvalues eigval. Then we sort both eigval and eigvec:\n\ni = np.argsort(-eigval)\neigval = -np.sort(-eigval)\neigvec = eigvec[:,i]\n\nThe eigendecomposition resulted in 200 eigenpairs, which is the size of s:\n\neigval.shape, eigvec.shape\n\nNot all of these modes will be important. There are more objective ways to find out how many we should keep, but for now, we will just look at the eigenvalues and look for any clear separation or “drop-off”:\n\nplt.bar(range(10), np.real(eigval[0:10]))\n\nThere is a pretty clear drop-off after the second eigenvalue, but let’s keep the first four to see the difference. And before truncating, we will sum over the eigenvalues for the next step.\n\neigval_sum = np.real(np.sum(eigval))\n\nr = 4\neigval = eigval[:r]\neigvec = eigvec[:, :r]\n\nTo transform the eigenvalues into explained variance, we need to divide by the sum of all eigenvalues and optionally multiply by 100 to get percentages:\n\npvar = np.real(eigval/eigval_sum*100)\npvar\n\nNote that we could have also divided by the trace of R:\n\nnp.real(eigval/np.trace(R)*100)\n\nTo get the PCs, we multiply the 2-dimensional data by the eigenvectors. Looking at the shape of the arrays can help us figure out if we need to transpose (.T) anything. What shape do we expect the PC data to have? There are four of them with 50 time steps each, so (4, 50) or (50, 4).\n\ndata_2d.shape, eigvec.shape\n\nWe need to transpose the data:\n\npcs = np.real(np.dot(data_2d.T, eigvec))\n\nThe PCs have dimensions (time, mode):\n\npcs.shape\n\nLets look at the PCs:\n\nplt.plot(pcs[:, 0], label='PC1')\nplt.plot(pcs[:, 1], label='PC2')\nplt.plot(pcs[:, 2], label='PC3', linestyle=':')\nplt.plot(pcs[:, 3], label='PC4', linestyle=':')\nplt.legend(loc='upper left')\nplt.ylabel('PC')\nplt.xlabel('$t$')\nplt.xlim(0, nt-1)\nplt.title('First four PCs')\n\nThe EOFs are just the eigenvectors, but we need to reshape them back into the two spatial dimensions x,y:\n\neofs = np.real(eigvec.reshape(10, 20, r))\n\nLet’s look at the leading EOF:\n\nplt.pcolormesh(x[:, :, 0], y[:, :, 0], eofs[:, :, 0], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar()\nplt.ylabel('$y$')\nplt.xlabel('$x$')\nplt.title('EOF1 (%.1f%%)' %pvar[0])\n\nThis looks like Mode 2 but with opposite sign and lower magnitude. We can attempt to reconstruct Mode 2 by multiplying this EOF with the corresponding PC:\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\n\nmode_2_reco_plot = ax[0].pcolormesh(x[:, :, 0], y[:, :, 0], eofs[:, :, 0]*pcs[2, 0], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar(mode_2_reco_plot, ax=ax[0])\nax[0].set_ylabel('$y$')\nax[0].set_xlabel('$x$')\nax[0].set_title('Reconstructed Mode 2 at $t=0$')\n\nmode_2_orig_plot = plt.pcolormesh(x[:, :, 2], y[:, :, 2], mode_2[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar(mode_2_orig_plot, ax=ax[1])\nax[1].set_ylabel('$y$')\nax[1].set_xlabel('$x$')\nax[1].set_title('Original Mode 2 at $t=0$')\n\nHere is the next EOF:\n\nplt.pcolormesh(x[:, :, 0], y[:, :, 0], eofs[:, :, 1], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar()\nplt.ylabel('$y$')\nplt.xlabel('$x$')\nplt.title('EOF2 (%.1f%%)' %pvar[1])\n\nThis is Mode 1, plus some noise and some apparent contamination (mode mixing) from Mode 2. We could reconstruct this mode, as well, but instead, let’s take a look at the next two modes:\n\nplt.pcolormesh(x[:, :, 0], y[:, :, 0], eofs[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar()\nplt.ylabel('$y$')\nplt.xlabel('$x$')\nplt.title('EOF3 (%.1f%%)' %pvar[2])\n\nplt.pcolormesh(x[:, :, 0], y[:, :, 0], eofs[:, :, 3], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar()\nplt.ylabel('$y$')\nplt.xlabel('$x$')\nplt.title('EOF4 (%.1f%%)' %pvar[3])\n\nEOF3 looks like some sort of residual from Mode 1, while EOF4 shows some zonal stripes that were not in our original data. Even though there is structure here, we should not interpret these as a meaningful or physical modes of variability in the data; they are artifacts of the method, particularly the orthogonality constraints. The very low explained variance is also an indication that the modes are probably not meaningful.\n\nPC3 shows an oscillation with a period of about 10 time steps and EOF3 shows a pattern that we might expect from the data, so if we didn’t have a priori knowledge about the data, we might have been tempted to interpret this mode as meaningful. We therefore have to be careful when interpreting the modes we find with EOF analyses.\n\n","type":"content","url":"/notebooks/numpy-eofs#do-the-analysis","position":15},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Exercise"},"type":"lvl2","url":"/notebooks/numpy-eofs#exercise","position":16},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Exercise"},"content":"Change the period of Mode 2 from 15 time steps to 20 time steps, bringing it closer in frequency to Mode 1. What happens?\n\n","type":"content","url":"/notebooks/numpy-eofs#exercise","position":17},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Bonus 1: adding noise"},"type":"lvl2","url":"/notebooks/numpy-eofs#bonus-1-adding-noise","position":18},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Bonus 1: adding noise"},"content":"\n\nReal geophysical data is rarely so clean. Let’s add some noise with a similar amplitude to the modes and see what happens. If the modes we constructed were modes of climate variability, this noise would be weather.\n\nnoisy_data = mode_1 + mode_2 + np.random.default_rng().normal(loc=0.0, scale=1.0, size=(nx, ny, nt))\n\nLet’s look at the data at t=0 for comparison:\n\nplt.pcolormesh(x[:, :, 2], y[:, :, 2], noisy_data[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar()\nplt.ylabel('$y$')\nplt.xlabel('$x$')\nplt.title('Noisy data at $t=0$')\n\nThe modes aren’t nearly as apparent with the noise added, just like real climate data.\n\nnoisy_data = (noisy_data.reshape(50, 10, 20) - noisy_data.mean(axis=2)).reshape(10, 20, 50)\nnoisy_data_2d = noisy_data.reshape(200, 50)\n\nn_R = np.cov(noisy_data_2d)\n(n_eigval, n_eigvec) = np.linalg.eig(n_R)\n\nn_i = np.argsort(-n_eigval)\nn_eigval = -np.sort(-n_eigval)\nn_eigvec = n_eigvec[:,i]\nr = 4\nn_eigval = n_eigval[:r]\nn_eigvec = n_eigvec[:, :r]\n\nn_pvar = np.real(n_eigval/np.trace(n_R)*100)\nn_pcs = np.real(np.dot(noisy_data_2d.T, n_eigvec))\nn_eofs = np.real(n_eigvec.reshape(10, 20, r))\n\nplt.plot(n_pcs[:, 0], label='PC1')\nplt.plot(n_pcs[:, 1], label='PC2')\nplt.plot(n_pcs[:, 2], label='PC3', linestyle=':')\nplt.plot(n_pcs[:, 3], label='PC4', linestyle=':')\nplt.legend(loc='upper left')\nplt.ylabel('PC')\nplt.xlabel('$t$')\nplt.xlim(0, nt-1)\nplt.title('First four PCs (noisy data)')\n\nn_fig, n_ax = plt.subplots(2, 2, figsize=(10, 5), layout='constrained')\n\nnoisy_eof1_plot = n_ax[0, 0].pcolormesh(x[:, :, 0], y[:, :, 0], n_eofs[:, :, 0], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar(noisy_eof1_plot, ax=n_ax[0, 0])\nn_ax[0, 0].set_ylabel('$y$')\nn_ax[0, 0].set_title('Noisy EOF1 (%.1f%%)' %n_pvar[0])\n\nnoisy_eof2_plot = n_ax[0, 1].pcolormesh(x[:, :, 0], y[:, :, 0], n_eofs[:, :, 1], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar(noisy_eof1_plot, ax=n_ax[0, 1])\nn_ax[0, 1].set_title('Noisy EOF2 (%.1f%%)' %n_pvar[1])\n\nnoisy_eof3_plot = n_ax[1, 0].pcolormesh(x[:, :, 0], y[:, :, 0], n_eofs[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar(noisy_eof3_plot, ax=n_ax[1, 0])\nn_ax[1, 0].set_ylabel('$y$')\nn_ax[1, 0].set_xlabel('$x$')\nn_ax[1, 0].set_title('Noisy EOF3 (%.1f%%)' %n_pvar[2])\n\nnoisy_eof4_plot = n_ax[1, 1].pcolormesh(x[:, :, 0], y[:, :, 0], n_eofs[:, :, 3], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar(noisy_eof4_plot, ax=n_ax[1, 1])\nn_ax[1, 1].set_xlabel('$x$')\nn_ax[1, 1].set_title('Noisy EOF4 (%.1f%%)' %n_pvar[3])\n\nThe EOF analysis has again successfully identified our two modes. The third and fourth modes explain more variance than in the clean example, but the spatial patterns strongly suggest that they are just noise.\n\n","type":"content","url":"/notebooks/numpy-eofs#bonus-1-adding-noise","position":19},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Bonus 2: method of snapshots"},"type":"lvl2","url":"/notebooks/numpy-eofs#bonus-2-method-of-snapshots","position":20},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Bonus 2: method of snapshots"},"content":"\n\nSometimes you have a lot more locations than time steps in your data, making computing the covariance matrix impractical, if not impossible. For example, consider a few years of 0.1° gridded climate data formatted as 32-bit floats. That’s (3600\\times1800)^2\\times 4\\approx 1.68\\times10^{14} bytes, or about 168 TB, required to hold the covariance matrix in memory.\n\nTo get around this issue, we turn to the method of snapshots \n\nSirovich, 1987. The only change in our simple example is that we compute the covariance of the transposed data, resulting in a matrix of dimension (time, time), which would be much more manageable in our 0.1° data example. Here is the result for our clean 2-mode data:\n\ns_R = np.cov(data_2d.T)\n(s_eigval, s_eigvec) = np.linalg.eig(s_R)\n\ns_i = np.argsort(-s_eigval)\ns_eigval = -np.sort(-s_eigval)\ns_eigvec = s_eigvec[:,s_i]\ns_eigval = s_eigval[:r]\ns_eigvec = s_eigvec[:, :r]\n\ns_pvar = np.real(s_eigval/np.trace(s_R)*100)\ns_pcs = np.real(s_eigvec)\ns_eofs = np.real(np.dot(data_2d, s_eigvec)).reshape(10, 20, r)\n\nplt.plot(s_pcs[:, 0], label='PC1')\nplt.plot(s_pcs[:, 1], label='PC2')\nplt.plot(s_pcs[:, 2], label='PC3', linestyle=':')\nplt.plot(s_pcs[:, 3], label='PC4', linestyle=':')\nplt.legend(loc='upper left')\nplt.ylabel('PC')\nplt.xlabel('$t$')\nplt.xlim(0, nt-1)\nplt.title('First four PCs (method of snapshots)')\n\ns_fig, s_ax = plt.subplots(2, 2, figsize=(10, 5), layout='constrained')\n\nmos_eof1_plot = s_ax[0, 0].pcolormesh(x[:, :, 0], y[:, :, 0], s_eofs[:, :, 0], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar(mos_eof1_plot, ax=s_ax[0, 0])\ns_ax[0, 0].set_ylabel('$y$')\ns_ax[0, 0].set_title('EOF1 (%.1f%%)' %s_pvar[0])\n\nmos_eof2_plot = s_ax[0, 1].pcolormesh(x[:, :, 0], y[:, :, 0], s_eofs[:, :, 1], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar(mos_eof1_plot, ax=s_ax[0, 1])\ns_ax[0, 1].set_title('EOF2 (%.1f%%)' %s_pvar[1])\n\nmos_eof3_plot = s_ax[1, 0].pcolormesh(x[:, :, 0], y[:, :, 0], s_eofs[:, :, 2], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar(mos_eof3_plot, ax=s_ax[1, 0])\ns_ax[1, 0].set_ylabel('$y$')\ns_ax[1, 0].set_xlabel('$x$')\ns_ax[1, 0].set_title('EOF3 (%.1f%%)' %s_pvar[2])\n\nmos_eof4_plot = s_ax[1, 1].pcolormesh(x[:, :, 0], y[:, :, 0], s_eofs[:, :, 3], cmap='RdBu_r', norm=CenteredNorm())\nplt.colorbar(mos_eof4_plot, ax=s_ax[1, 1])\ns_ax[1, 1].set_xlabel('$x$')\ns_ax[1, 1].set_title('EOF4 (%.1f%%)' %s_pvar[3])\n\nIt worked even better!\n\n\n\n","type":"content","url":"/notebooks/numpy-eofs#bonus-2-method-of-snapshots","position":21},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/numpy-eofs#summary","position":22},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl2":"Summary"},"content":"In this notebook, we implemented the EOF method on some synthetic data using NumPy. First, we generated two simple modes of variability and combined them. Then, our EOF analysis was able to largely isolate the modes as the first two EOF/PC pairs.","type":"content","url":"/notebooks/numpy-eofs#summary","position":23},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/numpy-eofs#whats-next","position":24},{"hierarchy":{"lvl1":"EOFs with NumPy","lvl3":"What’s next?","lvl2":"Summary"},"content":"In the next notebook, we will use a package called \n\nxeofs to find climate modes in real sea surface temperature data.","type":"content","url":"/notebooks/numpy-eofs#whats-next","position":25}]}